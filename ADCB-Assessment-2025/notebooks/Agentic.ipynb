{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a8e012",
   "metadata": {},
   "source": [
    "#### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90b8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Load reference doc\n",
    "base_path = os.path.dirname(\".\")\n",
    "ref_path = os.path.join(base_path, \"../docs/explanation_guide.txt\")\n",
    "\n",
    "\n",
    "def load_docs():\n",
    "    with open(ref_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "        # split by blank lines\n",
    "        paragraphs = [p.strip() for p in raw.split(\"\\n\\n\") if p.strip()]\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "docs = load_docs()\n",
    "vectorizer = TfidfVectorizer().fit(docs)\n",
    "doc_vectors = vectorizer.transform(docs)\n",
    "\n",
    "\n",
    "def retrieve_context(query, top_k=3):\n",
    "    \"\"\"Retrieve top K relevant chunks from the guide.\"\"\"\n",
    "    q_vec = vectorizer.transform([query])\n",
    "    scores = cosine_similarity(q_vec, doc_vectors)[0]\n",
    "    top_idx = scores.argsort()[-top_k:][::-1]\n",
    "    return [docs[i] for i in top_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095c26ad",
   "metadata": {},
   "source": [
    "#### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a95b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# Dummy LLM call (replace with OpenAI API)\n",
    "def call_llm(prompt: str) -> str:\n",
    "    return \"[LLM Explanation Placeholder]\\n\" + prompt[:200] + \"...\"\n",
    "\n",
    "\n",
    "# Optional helper to format key features\n",
    "def top_features_string(features: dict, top_k=5):\n",
    "    items = list(features.items())[:top_k]\n",
    "    return \"\\n\".join([f\"- {k}: {v}\" for k, v in items])\n",
    "\n",
    "\n",
    "def interpret_prediction(prediction, score):\n",
    "    if prediction == 1:\n",
    "        return \"High Risk\"\n",
    "    return \"Low Risk\"\n",
    "\n",
    "\n",
    "def explain_prediction(features: dict, prediction: int, risk_score: float):\n",
    "    label = interpret_prediction(prediction, risk_score)\n",
    "\n",
    "    query = f\"{label}, {', '.join(list(features.keys())[:3])}\"\n",
    "\n",
    "    retrieved = retrieve_context(query)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI banking risk analyst. Explain the model's decision.\n",
    "    \n",
    "    Model Prediction: {label} (risk score = {risk_score:.2f})\n",
    "\n",
    "    Customer Features:\n",
    "    {top_features_string(features)}\n",
    "\n",
    "    Relevant Context:\n",
    "    {json.dumps(retrieved, indent=2)}\n",
    "\n",
    "    Write a 4-6 line explanation in simple, factual terms.\n",
    "    \"\"\"\n",
    "    response = call_llm(prompt)\n",
    "\n",
    "    return {\n",
    "        \"prediction\": label,\n",
    "        \"risk_score\": risk_score,\n",
    "        \"retrieved_context\": retrieved,\n",
    "        \"explanation\": response,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aacef6",
   "metadata": {},
   "source": [
    "#### Example Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL OUTPUT ===\n",
      "High Risk 0.92\n",
      "\n",
      "=== RETRIEVED CONTEXT ===\n",
      "- Reasoning Patterns:\n",
      "- Pattern A: High income + long history → low risk.\n",
      "- Pattern B: High utilization + missed payments → high risk.\n",
      "- Pattern C: Young age + short credit history → medium/high risk.\n",
      "- Pattern D: Low utilization + no missed payments → low risk.\n",
      "- General Risk Rules:\n",
      "- Utilization above 70% significantly increases risk.\n",
      "- More than 1 missed payment in last 12 months increases risk.\n",
      "- A long clean credit history decreases risk.\n",
      "- High income-to-debt ratio reduces risk.\n",
      "- Younger customers with short histories may show more volatility.\n",
      "- Feature Meanings:\n",
      "- income: Monthly customer income. Higher income indicates more repayment capacity.\n",
      "- utilization: Percentage of credit used relative to the limit.\n",
      "- missed_payments: Count of missed or delayed payments.\n",
      "- credit_history_length: Number of years since first credit account.\n",
      "- age: Customer age in years.\n",
      "- debt_to_income: Total debt divided by monthly income.\n",
      "\n",
      "=== FINAL EXPLANATION ===\n",
      "[LLM Explanation Placeholder]\n",
      "\n",
      "    You are an AI banking risk analyst. Explain the model's decision.\n",
      "\n",
      "    Model Prediction: High Risk (risk score = 0.92)\n",
      "\n",
      "    Customer Features:\n",
      "    - income: 4800\n",
      "- utilization: 0.82\n",
      "- missed_paym...\n"
     ]
    }
   ],
   "source": [
    "# Example real row (replace with real dataset row)\n",
    "features = {\n",
    "\"income\": 4800,\n",
    "\"utilization\": 0.82,\n",
    "\"missed_payments\": 3,\n",
    "\"credit_history_length\": 1.2,\n",
    "\"age\": 24,\n",
    "\"debt_to_income\": 0.54,\n",
    "}\n",
    "\n",
    "\n",
    "# todo: replace with actual model's predictions\n",
    "prediction = 1\n",
    "risk_score = 0.92\n",
    "\n",
    "\n",
    "result = explain_prediction(features, prediction, risk_score)\n",
    "\n",
    "\n",
    "print(\"=== MODEL OUTPUT ===\")\n",
    "print(result[\"prediction\"], result[\"risk_score\"])\n",
    "\n",
    "\n",
    "print(\"\\n=== RETRIEVED CONTEXT ===\")\n",
    "for c in result[\"retrieved_context\"]:\n",
    "    print(\"-\", c)\n",
    "\n",
    "\n",
    "print(\"\\n=== FINAL EXPLANATION ===\")\n",
    "print(result[\"explanation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8270b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adcb-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
